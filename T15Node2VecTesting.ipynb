{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets and libraries"
      ],
      "metadata": {
        "id": "GQ-btGWa9HfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxJ-3SHr66pH"
      },
      "outputs": [],
      "source": [
        "!gdown 1SaSq8kwvNmxq2HoQBenhXC3ejM8BU70d\n",
        "!gdown 1uGv2afj67P9BGEMwFPyv_IopjMzaqMuG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, GRU, Embedding, Dropout, LSTM, Concatenate, SimpleRNN, Bidirectional\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "Wa4D5S3xB4Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_str_to_npa(s):\n",
        "  data_list = s.split(' ')\n",
        "  data_array = np.array([float(num) for num in data_list])\n",
        "  return data_array"
      ],
      "metadata": {
        "id": "4YzGLdVS9f0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.read_csv('t15_text_n2v.csv', encoding='utf-8')\n",
        "bert_embeddings1 = np.load('t15_bert_emb.npy')\n",
        "d1['bert_embeddings'] = list(bert_embeddings1)"
      ],
      "metadata": {
        "id": "hdMdpR6S9LUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_embeddings, test_embeddings, train_dw, test_dw, train_labels, test_labels = train_test_split(\n",
        "    np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(train_embeddings.shape[1], train_embeddings.shape[2]), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  rnn_output = Bidirectional(LSTM(64))(text_input)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "7iLoPFUJ_zlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 32 dimensions"
      ],
      "metadata": {
        "id": "ZBZjD3Wi-4l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_lists = []\n",
        "for i in range(1, 7):\n",
        "    filename = f\"t15/32d/output_{i}.txt\"\n",
        "    with open(filename, \"r\") as file:\n",
        "        emb_list = [line.strip() for line in file]\n",
        "        emb_lists.append(emb_list)\n",
        "\n",
        "n2v_1, n2v_2, n2v_3, n2v_4, n2v_5, n2v_6 = emb_lists"
      ],
      "metadata": {
        "id": "ivH8eaHK-3_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 1)"
      ],
      "metadata": {
        "id": "mZ-QHqwG-YCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/11.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_1\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "hPRsWIQQ-e8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 1)"
      ],
      "metadata": {
        "id": "bStx82B_AIaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/051.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_2\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "gvs2hCjmAQgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 0.5)"
      ],
      "metadata": {
        "id": "gKSXehspAJgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/105.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_3\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "5nG113CNAawx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 0.5)"
      ],
      "metadata": {
        "id": "anhm_ULiAJup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/0505.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_4\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "s8k6LW5DAheP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (2, 1)"
      ],
      "metadata": {
        "id": "rsj0tZ4iAJ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/21.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_5\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "_qwOcYEYAqtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 2)"
      ],
      "metadata": {
        "id": "AhYzdovGAKBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/32d/21.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_6\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "q-eaXsgUA0Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100 dimensions"
      ],
      "metadata": {
        "id": "BA2XJATEA_Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_lists = []\n",
        "for i in range(1, 7):\n",
        "    filename = f\"t15/100d/output_{i}.txt\"\n",
        "    with open(filename, \"r\") as file:\n",
        "        emb_list = [line.strip() for line in file]\n",
        "        emb_lists.append(emb_list)\n",
        "\n",
        "n2v_1, n2v_2, n2v_3, n2v_4, n2v_5, n2v_6 = emb_lists"
      ],
      "metadata": {
        "id": "ZxvimequBXvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 1)"
      ],
      "metadata": {
        "id": "tN-CFdqyBCyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/11.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_1\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "M-cUQ_gpBbZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 1)"
      ],
      "metadata": {
        "id": "1KFUHDa3BC9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/051.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_2\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "4722k3uwBegm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 0.5)"
      ],
      "metadata": {
        "id": "b36vyc5iBDEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/105.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_3\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "rmt4uqVZBhCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 0.5)"
      ],
      "metadata": {
        "id": "kHVqQLMgBDKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/0505.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_4\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "G0KaiHPoBjRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (2, 1)"
      ],
      "metadata": {
        "id": "hL50CjvRBDPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/21.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_5\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "UKMnu8lYBmlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 2)"
      ],
      "metadata": {
        "id": "9d133tbuBDTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = d1.drop('n2v', axis=1)\n",
        "with open('t15/100d/12.txt', 'a') as f:\n",
        "  d1['n2v'] = n2v_6\n",
        "  d1['n2v'] = d1['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = BiLSTM_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d1['bert_embeddings'].tolist()), np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "CeE36209BB2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}