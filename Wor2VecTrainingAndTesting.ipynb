{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5PNpSgPsfgWv",
        "p-1WAMMPrenf",
        "JRTX5B_zpF5e",
        "6sBCfadNutV1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Datasets and libraries"
      ],
      "metadata": {
        "id": "5PNpSgPsfgWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1SaSq8kwvNmxq2HoQBenhXC3ejM8BU70d\n",
        "!gdown 1uGv2afj67P9BGEMwFPyv_IopjMzaqMuG"
      ],
      "metadata": {
        "id": "mdAbTA1JftgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eGAiwrRaPE9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Input, Dense, GRU, Embedding, Dropout, LSTM, Concatenate, SimpleRNN, Bidirectional\n",
        "from keras.models import Model\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "p-1WAMMPrenf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_npa(s):\n",
        "  data_list = s.split(' ')\n",
        "  c = 0\n",
        "  for x in data_list:\n",
        "    if x == '':\n",
        "      c += 1\n",
        "  for i in range(c):\n",
        "    data_list.remove('')\n",
        "  data_array = np.array([float(num) for num in data_list])\n",
        "  return data_array\n",
        "\n",
        "def remove_punctuations(data):\n",
        "    punct_tag=re.compile(r'[^\\w\\s]')\n",
        "    data=punct_tag.sub(r'',data)\n",
        "    return data\n",
        "\n",
        "def remove_url(data):\n",
        "    url_tag=re.compile(r'URL')\n",
        "    data=url_tag.sub(r'', data)\n",
        "    return data\n",
        "\n",
        "def remove_double_spaces(data):\n",
        "    data = re.sub(' +', ' ', data)\n",
        "    return data\n",
        "\n",
        "def get_tokens(data):\n",
        "    return data.split(' ')\n",
        "\n",
        "def remove_stopwords(data):\n",
        "    data = ' '.join([word for word in data.split() if word not in stop_words])\n",
        "    return data"
      ],
      "metadata": {
        "id": "WA_KpL9grbNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.read_csv('t15_text_n2v.csv', encoding='utf-8')\n",
        "d2 = pd.read_csv('t16_text_n2v.csv', encoding='utf-8')\n",
        "\n",
        "d1['n2v'] = d1['n2v'].apply(lambda x: x.replace('[', ''))\n",
        "d1['n2v'] = d1['n2v'].apply(lambda x: x.replace(']', ''))\n",
        "d1['n2v'] = d1['n2v'].apply(lambda x: str_to_npa(x))\n",
        "\n",
        "d2['n2v'] = d2['n2v'].apply(lambda x: x.replace('[', ''))\n",
        "d2['n2v'] = d2['n2v'].apply(lambda x: x.replace(']', ''))\n",
        "d2['n2v'] = d2['n2v'].apply(lambda x: str_to_npa(x))\n",
        "\n",
        "content1 = d1['text']\n",
        "content2 = d2['text']\n",
        "\n",
        "content1=content1.apply(lambda z: remove_punctuations(z))\n",
        "content1=content1.apply(lambda z: remove_url(z))\n",
        "content1=content1.apply(lambda z: remove_double_spaces(z))\n",
        "content1=content1.apply(lambda z: remove_stopwords(z))\n",
        "content1=content1.apply(lambda z: get_tokens(z))\n",
        "\n",
        "content2=content2.apply(lambda z: remove_punctuations(z))\n",
        "content2=content2.apply(lambda z: remove_url(z))\n",
        "content2=content2.apply(lambda z: remove_double_spaces(z))\n",
        "content2=content2.apply(lambda z: remove_stopwords(z))\n",
        "content2=content2.apply(lambda z: get_tokens(z))\n",
        "\n",
        "# Encoding for testing\n",
        "model_enc = {1 : 'RNN',\n",
        "             2 : 'BiRNN',\n",
        "             3 : 'GRU',\n",
        "             4 : 'BiGRU',\n",
        "             5 : 'LSTM',\n",
        "             6 : 'BiLSTM'}\n",
        "\n"
      ],
      "metadata": {
        "id": "6p7Y2_qbpMfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter15"
      ],
      "metadata": {
        "id": "JRTX5B_zpF5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 0\n",
        "for text in content1:\n",
        "  if maxlen < len(text):\n",
        "    maxlen = len(text)\n",
        "e1 = np.load('t15_w2v_emb_matrix.npy')\n",
        "vocab1_size = e1[0].shape"
      ],
      "metadata": {
        "id": "9Rr3dzJWtRDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Node Embeddings"
      ],
      "metadata": {
        "id": "860LfYEFost9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "yriLbprJo8uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in range(1, 11):\n",
        "  # randomize train-test-split\n",
        "  random_state = random.randint(1, 100)\n",
        "  train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
        "        content1, d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "  # tokenize text input\n",
        "  tokenizer1 = Tokenizer(num_words = vocab1_size)\n",
        "  tokenizer1.fit_on_texts(train_embeddings)\n",
        "  sequences_train1 = tokenizer1.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train1, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test1= tokenizer1.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test1, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t15/w2v/without/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit(train_embeddings, train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate(test_embeddings, test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict(test_embeddings)\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "xVkV3cG6pghB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Node2Vec Node Embeddings"
      ],
      "metadata": {
        "id": "xQ8beAPLqnMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "    content1, np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "4fl-pi3Zqz7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in range(1, 11):\n",
        "  # randomize train-test-split\n",
        "  random_state = random.randint(1, 100)\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      content1, np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "  )\n",
        "\n",
        "  # tokenize\n",
        "  tokenizer1 = Tokenizer(num_words = vocab1_size)\n",
        "  tokenizer1.fit_on_texts(train_embeddings)\n",
        "  sequences_train1 = tokenizer1.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train1, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test1= tokenizer1.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test1, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t15/w2v/n2v/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit([train_embeddings, train_n2v], train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate([test_embeddings, test_n2v], test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict([test_embeddings, test_n2v])\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "C3X8ReVVriQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With DeepWalk Node Embeddings"
      ],
      "metadata": {
        "id": "nPcG-us4luCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb = np.load('100d/t15_dw_emb.npy')\n",
        "d1['dw'] = list(node_emb)\n",
        "\n",
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e1).shape[0], 100, weights=[e1], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "6lqF7bLnbePD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(1, 11):\n",
        "  # randomize\n",
        "  random_state = random.randint(1, 100)\n",
        "  train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "        content1, np.array(d1['dw'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "\n",
        "  # tokenize\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      content1, np.array(d1['dw'].tolist()), d1['label'].values, test_size=0.2, random_state=42\n",
        "  )\n",
        "  tokenizer1 = Tokenizer(num_words = vocab1_size)\n",
        "  tokenizer1.fit_on_texts(train_embeddings)\n",
        "  sequences_train1 = tokenizer1.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train1, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test1= tokenizer1.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test1, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t15/w2v/dw/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit([train_embeddings, train_n2v], train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate([test_embeddings, test_n2v], test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict([test_embeddings, test_n2v])\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "tQwue73MmSG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter16"
      ],
      "metadata": {
        "id": "6sBCfadNutV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 0\n",
        "for text in content2:\n",
        "  if maxlen < len(text):\n",
        "    maxlen = len(text)\n",
        "e2 = np.load('t16_w2v_emb_matrix.npy')\n",
        "vocab2_size = e2[0].shape"
      ],
      "metadata": {
        "id": "SNnA2gMFvBer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Node Embeddings"
      ],
      "metadata": {
        "id": "DIxRSq0yu0iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  hidden = Dense(32, activation='relu')(rnn_output)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=text_input, outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "LvwvcqjWu_1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in range(1, 11):\n",
        "  # randomize train-test-split\n",
        "  random_state = random.randint(1, 100)\n",
        "  train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
        "        content2, d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "  # tokenize text input\n",
        "  tokenizer2 = Tokenizer(num_words = vocab2_size)\n",
        "  tokenizer2.fit_on_texts(train_embeddings)\n",
        "  sequences_train2 = tokenizer2.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train2, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test2= tokenizer2.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test2, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t16/w2v/without/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit(train_embeddings, train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate(test_embeddings, test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict(test_embeddings)\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "6CKbs5ZmvNjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Node2Vec Node Embeddings"
      ],
      "metadata": {
        "id": "nFIla_FXu2eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "    content2, np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "DwNn6hLKvwfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in range(1, 11):\n",
        "  # randomize train-test-split\n",
        "  random_state = random.randint(1, 100)\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      content2, np.array(d1['n2v'].tolist()), d1['label'].values, test_size=0.2, random_state=random_state\n",
        "  )\n",
        "\n",
        "  # tokenize\n",
        "  tokenizer2 = Tokenizer(num_words = vocab2_size)\n",
        "  tokenizer2.fit_on_texts(train_embeddings)\n",
        "  sequences_train2 = tokenizer2.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train2, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test2= tokenizer1.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test2, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t16/w2v/n2v/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit([train_embeddings, train_n2v], train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate([test_embeddings, test_n2v], test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict([test_embeddings, test_n2v])\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "RGGFnnkAv4x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With DeepWalk Node Embeddings"
      ],
      "metadata": {
        "id": "kx6sYF73u5EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb = np.load('100d/t16_dw_emb.npy')\n",
        "d2['dw'] = list(node_emb)\n",
        "\n",
        "def RNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = SimpleRNN(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiRNN_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(SimpleRNN(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def GRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = GRU(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiGRU_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(GRU(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def LSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = LSTM(64)(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model\n",
        "\n",
        "def BiLSTM_model():\n",
        "  text_input = Input(shape=(maxlen,), name='text_input')\n",
        "  graph_input = Input(shape=(node_emb.shape[1],), name='graph_input')\n",
        "  embedding_layer = Embedding(np.array(e2).shape[0], 100, weights=[e2], trainable=False)(text_input)\n",
        "  rnn_output = Bidirectional(LSTM(64))(embedding_layer)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "rGeRb9ynuzGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(1, 11):\n",
        "  # randomize\n",
        "  random_state = random.randint(1, 100)\n",
        "  train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "        content1, np.array(d2['dw'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "  # tokenize\n",
        "  tokenizer2 = Tokenizer(num_words = vocab2_size)\n",
        "  tokenizer2.fit_on_texts(train_embeddings)\n",
        "  sequences_train2 = tokenizer2.texts_to_sequences(train_embeddings)\n",
        "  train_embeddings = pad_sequences(sequences_train2, maxlen=maxlen ,padding='post')\n",
        "\n",
        "  sequences_test2= tokenizer2.texts_to_sequences(test_embeddings)\n",
        "  test_embeddings = pad_sequences(sequences_test2, maxlen=maxlen,padding='post')\n",
        "\n",
        "  filename = \"results/t16/w2v/dw/output\" + str(j) + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  for i in model_enc.keys():\n",
        "      if model_enc[i] == 'RNN':\n",
        "        model = RNN_model()\n",
        "      elif model_enc[i] == 'BiRNN':\n",
        "        model = BiRNN_model()\n",
        "      elif model_enc[i] == 'GRU':\n",
        "        model = GRU_model()\n",
        "      elif model_enc[i] == 'BiGRU':\n",
        "        model = BiGRU_model()\n",
        "      elif model_enc[i] == 'LSTM':\n",
        "        model = LSTM_model()\n",
        "      else:\n",
        "        model = BiLSTM_model()\n",
        "      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      print(f\"Training Model {model_enc[i]}\")\n",
        "      model.fit([train_embeddings, train_n2v], train_labels, epochs=8, batch_size=64, validation_split=0.2)\n",
        "      score = model.evaluate([test_embeddings, test_n2v], test_labels, verbose=0)\n",
        "      file.write(f\"Model {model_enc[i]} Test Accuracy: {score[1]}\" + '\\n')\n",
        "      y_pred = model.predict([test_embeddings, test_n2v])\n",
        "      y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "      report = classification_report(test_labels, y_pred)\n",
        "      file.write(report + '\\n')\n",
        "\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "niZVAtGYwPyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}