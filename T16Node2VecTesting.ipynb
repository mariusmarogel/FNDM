{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets and libraries"
      ],
      "metadata": {
        "id": "IGSF2Rv1SxSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1SaSq8kwvNmxq2HoQBenhXC3ejM8BU70d\n",
        "!gdown 1uGv2afj67P9BGEMwFPyv_IopjMzaqMuG"
      ],
      "metadata": {
        "id": "e-ocYD0sCOmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, GRU, Embedding, Dropout, LSTM, Concatenate, SimpleRNN, Bidirectional\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "BoRs8Ap_CQ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_str_to_npa(s):\n",
        "  data_list = s.split(' ')\n",
        "  data_array = np.array([float(num) for num in data_list])\n",
        "  return data_array"
      ],
      "metadata": {
        "id": "ot_X3BqICTI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = pd.read_csv('t16_text_n2v.csv', encoding='utf-8')\n",
        "bert_embeddings2 = np.load('t16_bert_emb.npy')\n",
        "d2['bert_embeddings'] = list(bert_embeddings2)"
      ],
      "metadata": {
        "id": "7rnfkomECWEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_embeddings, test_embeddings, train_dw, test_dw, train_labels, test_labels = train_test_split(\n",
        "    np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def RNN_model():\n",
        "  text_input = Input(shape=(train_embeddings.shape[1], train_embeddings.shape[2]), name='text_input')\n",
        "  graph_input = Input(shape=(train_n2v.shape[1],), name='graph_input')\n",
        "  rnn_output = RNN(64)(text_input)\n",
        "  rnn_output = Dropout(0.2)(rnn_output)\n",
        "  graph_output = Dense(32, activation='relu')(graph_input)\n",
        "  concatenated = Concatenate()([rnn_output, graph_output])\n",
        "  hidden = Dense(32, activation='relu')(concatenated)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=[text_input, graph_input], outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "7lbK-HZiCbkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 32 dimensions"
      ],
      "metadata": {
        "id": "d0QcCZWvmT6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_lists = []\n",
        "\n",
        "for i in range(1, 7):\n",
        "    filename = f\"t16/32/output_{i}.txt\"\n",
        "    with open(filename, \"r\") as file:\n",
        "        emb_list = [line.strip() for line in file]\n",
        "        emb_lists.append(emb_list)\n",
        "\n",
        "n2v_1, n2v_2, n2v_3, n2v_4, n2v_5, n2v_6 = emb_lists"
      ],
      "metadata": {
        "id": "ci8kihDmTxNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 1)"
      ],
      "metadata": {
        "id": "Q7LPZb9mBDhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/11.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_1\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "Ts1af8fZBH-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 1)"
      ],
      "metadata": {
        "id": "DD81pwjTeXJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/051.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_2\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "Yl-LhHnUeh6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 0.5)"
      ],
      "metadata": {
        "id": "Rjcz8CG0ftQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/105.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_3\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "lT5450Rsgh8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 0.5)"
      ],
      "metadata": {
        "id": "JEhT0G3ViCqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/0505.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_4\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "8wtkzXHoiHLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (2, 1)"
      ],
      "metadata": {
        "id": "347HGOmpjMnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/21.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_5\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "RDO-MiyHjO84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 2)"
      ],
      "metadata": {
        "id": "3YzIFABAkTDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/32d/12.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_6\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "JB7siGX5kWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100 dimensions"
      ],
      "metadata": {
        "id": "ENYR3NYSox6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 1)"
      ],
      "metadata": {
        "id": "dEn3u09ppA-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/11.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_1\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "NMzm6_iWo3XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 1)"
      ],
      "metadata": {
        "id": "b0ztPMCFpVCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/051.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_2\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "S6JuWsUBpYJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 0.5)"
      ],
      "metadata": {
        "id": "4B3eTYOBpjFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/105.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_3\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "AkxK9-Gcpl2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (0.5, 0.5)"
      ],
      "metadata": {
        "id": "wIQaE614pmQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/0505.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_4\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "WqGJX792pojh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (2, 1)"
      ],
      "metadata": {
        "id": "uMAHzlalpo54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/21.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_5\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "x1tz-RlWprCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (P, Q) = (1, 2)"
      ],
      "metadata": {
        "id": "UYWXL8h8prUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d2.drop('n2v', axis=1)\n",
        "with open('t16/100d/12.txt', 'a') as f:\n",
        "  d2['n2v'] = n2v_6\n",
        "  d2['n2v'] = d2['n2v'].apply(lambda x: list_str_to_npa(x))\n",
        "  for i in range(1, 11):\n",
        "    model = RNN_model()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "    random_state = random.randint(1, 100)\n",
        "    f.write(f\"iteration_{i}\" + '\\n')\n",
        "    train_embeddings, test_embeddings, train_n2v, test_n2v, train_labels, test_labels = train_test_split(\n",
        "      np.array(d2['bert_embeddings'].tolist()), np.array(d2['n2v'].tolist()), d2['label'].values, test_size=0.2, random_state=random_state\n",
        "    )\n",
        "    model.fit([train_embeddings, train_n2v], train_labels, epochs=30, batch_size=32, validation_split=0.2)\n",
        "    y_pred = model.predict([test_embeddings, test_n2v])\n",
        "    y_pred = [1.0 if p > 0.5 else 0 for p in y_pred]\n",
        "    report = classification_report(test_labels, y_pred)\n",
        "    f.write(report + '\\n')"
      ],
      "metadata": {
        "id": "3ABpu3-mptxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}