{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ezrAEf7WKAI8"
      },
      "source": [
        "# Import Datasets and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga0m5y93KCfD"
      },
      "outputs": [],
      "source": [
        "# Downloading csv datasets for Twitter15 and Twitter16 with links\n",
        "!gdown 1SaSq8kwvNmxq2HoQBenhXC3ejM8BU70d\n",
        "!gdown 1uGv2afj67P9BGEMwFPyv_IopjMzaqMuG\n",
        "!gdown 1jfWwc8g-rS0G3oS5oKsydq8QXU7vev72\n",
        "!gdown 1z0vGTX5LGaMn-zjSpT9uIePXwi0qDBUz\n",
        "!mkdir Twitter15\n",
        "!mkdir Twitter16\n",
        "!unzip tree15.zip -d 'Twitter15'\n",
        "!unzip tree16.zip -d 'Twitter16'\n",
        "!pip install node2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIImQ8sUMz72"
      },
      "outputs": [],
      "source": [
        "from node2vec import Node2Vec as n2v\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZeXPdtXL6dL"
      },
      "outputs": [],
      "source": [
        "d1 = pd.read_csv('t15_text_n2v.csv', encoding='utf-8')\n",
        "d2 = pd.read_csv('t16_text_n2v.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8HoM9OtKwLQ"
      },
      "outputs": [],
      "source": [
        "# functions for reading a graph from a tree_file, and for drawing\n",
        "\n",
        "tree_dir = '/content/Twitter15/tree'\n",
        "def read_graph_from_file(tree_dir, filename):\n",
        "    with open(os.path.join(tree_dir, filename), 'r') as file:\n",
        "        G = nx.DiGraph()\n",
        "        for line in file:\n",
        "            if '->' in line:\n",
        "                parent_node, child_node = line.strip().split('->')\n",
        "                G.add_edge(parent_node, child_node)\n",
        "    return G\n",
        "def draw_graph(G):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    pos = nx.kamada_kawai_layout(G)\n",
        "    node_options = {\"node_color\": \"red\", \"node_size\":30}\n",
        "    edge_options = {\"width\": .5, \"alpha\": .5, \"edge_color\":\"black\"}\n",
        "    nx.draw_networkx_nodes(G, pos, **node_options)\n",
        "    nx.draw_networkx_edges(G, pos, **edge_options)\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "loIjhxeWP6z_"
      },
      "source": [
        "# 32-dimensional Node2Vec Embeddings for Twitter15 and Twitter16"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UUraA0EtRIM9"
      },
      "source": [
        "Each cell has its parameters declared for running separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j73j_u_rP_ed"
      },
      "outputs": [],
      "source": [
        "# Twitter15 Node2Vec Embeddings\n",
        "emb_lists = []\n",
        "dimensions = 32\n",
        "walk_length = 10\n",
        "num_walks = 10\n",
        "window = 10\n",
        "min_count = 1\n",
        "batch_words = 4\n",
        "pq_values = [(1, 1), (0.5, 1), (1, 0.5), (0.5, 0.5), (2, 1), (1, 2)]\n",
        "\n",
        "for i, pq in enumerate(pq_values, start=1):\n",
        "    emb_list = []\n",
        "    p, q = pq\n",
        "\n",
        "    for tweet_id in d1['tweet_id']:\n",
        "        filename = str(tweet_id) + \".txt\"\n",
        "        G = read_graph_from_file(tree_dir, filename)\n",
        "        model = n2v(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=4)\n",
        "        model = model.fit(window=window, min_count=min_count, batch_words=batch_words)\n",
        "        #node embedding of the source tweet -> node_0 = root, node_1 = source\n",
        "        node = list(G.nodes())[1]\n",
        "        emb_list.append(model.wv.get_vector(node))\n",
        "\n",
        "    emb_lists.append(emb_list)\n",
        "\n",
        "    with open(f\"32d/t15_output_{i}.txt\", \"w\") as file:\n",
        "        for emb in emb_list:\n",
        "            emb_str = ' '.join(str(x) for x in emb)\n",
        "            file.write(emb_str + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ9NfP_mQCPZ"
      },
      "outputs": [],
      "source": [
        "#Twitter16 Node2Vec Embeddings\n",
        "emb_lists = []\n",
        "dimensions = 100\n",
        "walk_length = 10\n",
        "num_walks = 10\n",
        "window = 10\n",
        "min_count = 1\n",
        "batch_words = 4\n",
        "pq_values = [(1, 1), (0.5, 1), (1, 0.5), (0.5, 0.5), (2, 1), (1, 2)]\n",
        "\n",
        "for i, pq in enumerate(pq_values, start=1):\n",
        "    emb_list = []\n",
        "    p, q = pq\n",
        "\n",
        "    for tweet_id in d2['tweet_id']:\n",
        "        filename = str(tweet_id) + \".txt\"\n",
        "        G = read_graph_from_file(tree_dir, filename)\n",
        "        model = n2v(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=4)\n",
        "        model = model.fit(window=window, min_count=min_count, batch_words=batch_words)\n",
        "        #node embedding of the source tweet -> node_0 = root, node_1 = source\n",
        "        node = list(G.nodes())[1]\n",
        "        emb_list.append(model.wv.get_vector(node))\n",
        "\n",
        "    emb_lists.append(emb_list)\n",
        "\n",
        "    with open(f\"32d/t16_output_{i}.txt\", \"w\") as file:\n",
        "        for emb in emb_list:\n",
        "            emb_str = ' '.join(str(x) for x in emb)\n",
        "            file.write(emb_str + '\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pew2t6HjORRg"
      },
      "source": [
        "# 100-dimensional Node2Vec Embeddings for Twitter15 and Twitter16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P87IpHaLGo2"
      },
      "outputs": [],
      "source": [
        "# Twitter15 Node2Vec Embeddings\n",
        "emb_lists = []\n",
        "dimensions = 100\n",
        "walk_length = 10\n",
        "num_walks = 10\n",
        "window = 10\n",
        "min_count = 1\n",
        "batch_words = 4\n",
        "pq_values = [(1, 1), (0.5, 1), (1, 0.5), (0.5, 0.5), (2, 1), (1, 2)]\n",
        "\n",
        "for i, pq in enumerate(pq_values, start=1):\n",
        "    emb_list = []\n",
        "    p, q = pq\n",
        "\n",
        "    for tweet_id in d1['tweet_id']:\n",
        "        filename = str(tweet_id) + \".txt\"\n",
        "        G = read_graph_from_file(tree_dir, filename)\n",
        "        model = n2v(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=4)\n",
        "        model = model.fit(window=window, min_count=min_count, batch_words=batch_words)\n",
        "        #node embedding of the source tweet -> node_0 = root, node_1 = source\n",
        "        node = list(G.nodes())[1]\n",
        "        emb_list.append(model.wv.get_vector(node))\n",
        "\n",
        "    emb_lists.append(emb_list)\n",
        "\n",
        "    with open(f\"100d/t15_output_{i}.txt\", \"w\") as file:\n",
        "        for emb in emb_list:\n",
        "            emb_str = ' '.join(str(x) for x in emb)\n",
        "            file.write(emb_str + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z8NYi-wN8ar"
      },
      "outputs": [],
      "source": [
        "#Twitter16 Node2Vec Embeddings\n",
        "emb_lists = []\n",
        "dimensions = 100\n",
        "walk_length = 10\n",
        "num_walks = 10\n",
        "window = 10\n",
        "min_count = 1\n",
        "batch_words = 4\n",
        "pq_values = [(1, 1), (0.5, 1), (1, 0.5), (0.5, 0.5), (2, 1), (1, 2)]\n",
        "\n",
        "for i, pq in enumerate(pq_values, start=1):\n",
        "    emb_list = []\n",
        "    p, q = pq\n",
        "\n",
        "    for tweet_id in d2['tweet_id']:\n",
        "        filename = str(tweet_id) + \".txt\"\n",
        "        G = read_graph_from_file(tree_dir, filename)\n",
        "        model = n2v(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=4)\n",
        "        model = model.fit(window=window, min_count=min_count, batch_words=batch_words)\n",
        "        #node embedding of the source tweet -> node_0 = root, node_1 = source\n",
        "        node = list(G.nodes())[1]\n",
        "        emb_list.append(model.wv.get_vector(node))\n",
        "\n",
        "    emb_lists.append(emb_list)\n",
        "\n",
        "    with open(f\"100d/t16_output_{i}.txt\", \"w\") as file:\n",
        "        for emb in emb_list:\n",
        "            emb_str = ' '.join(str(x) for x in emb)\n",
        "            file.write(emb_str + '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "loIjhxeWP6z_",
        "pew2t6HjORRg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
